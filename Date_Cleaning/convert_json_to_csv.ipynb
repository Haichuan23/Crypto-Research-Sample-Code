{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file converts a json file into csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code transforms a json file into a csv file\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "with open('/Users/haichuan/Desktop/current_vaults.json') as json_file:\n",
    "    jsondata = json.load(json_file)\n",
    "print(jsondata)\n",
    "data_file = open('/Users/haichuan/Desktop/current_vaults3.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(data_file)\n",
    " \n",
    "count = 0\n",
    "for data in jsondata:\n",
    "    if count == 0:\n",
    "        header = data.keys()\n",
    "        csv_writer.writerow(header)\n",
    "        count += 1\n",
    " \n",
    "data_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the json format is a bit more tricky...\n",
    "### This is a sample code for conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from statistics import mean\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename: str) -> dict:\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            # load the json file into data\n",
    "            data = json.loads(f.read())\n",
    "    except:\n",
    "        raise Exception(f\"Reading {filename} file encountered an error\")\n",
    "  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_class = [\"xxx_S\"]\n",
    "borrow_class = [\"xxx_B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_date = datetime(2022,4,1)\n",
    "    new_data = []\n",
    "\n",
    "    for single_date in (start_date + timedelta(n) for n in range(30)):\n",
    "        file_name = '_'+ str(single_date) + '.json'\n",
    "        dataset = read_json(file_name)\n",
    "        flag = 0\n",
    "\n",
    "        for i in range(len(dataset[\"markets\"])):\n",
    "            check = dataset[\"markets\"][i][\"target_market\"]\n",
    "            if (check == \"xxx\"): ### capture key word\n",
    "                flag = 1\n",
    "                compound_index_dict = dataset[\"markets\"][i][\"index_dict\"]\n",
    "\n",
    "                data = dataset[\"markets\"][i]['accounts_data']\n",
    "                def normalize_json(data: list) -> dict:\n",
    "                        # everytime normalize a single data from a json format into a list of \n",
    "                        # dictionaries\n",
    "                        new_data_point = dict()\n",
    "                        new_data_point['date'] = str(single_date)\n",
    "                        for point in data:\n",
    "                            if point == \"supply_vector\":\n",
    "                                for j in range(len(supply_class)):\n",
    "                                    key_s = supply_class[j]\n",
    "                                    index_key = key_s.split(\"_\")[0]\n",
    "                                    true_index = compound_index_dict[index_key]\n",
    "                                    new_data_point[key_s] = data[point][true_index]\n",
    "                            elif point == \"borrow_vector\":\n",
    "                                for j in range(len(borrow_class)):\n",
    "                                    key_s = borrow_class[j]\n",
    "                                    index_key = key_s.split(\"_\")[0]\n",
    "                                    true_index = compound_index_dict[index_key]\n",
    "                                    new_data_point[key_s] = data[point][true_index]\n",
    "                            else:\n",
    "                                new_data_point[point] = data[point]\n",
    "                        #print(new_data_point[\"account_address\"])   \n",
    "                        new_data.append(new_data_point)\n",
    "                \n",
    "                for i in range(len(data)):\n",
    "                    normalize_json(data[i])\n",
    "                \n",
    "                if (flag == 0):\n",
    "                    print(f\"{single_date} doesn't has xxx data\")\n",
    "\n",
    "                break\n",
    "\n",
    "        \n",
    "    keys = new_data[0].keys()\n",
    "        \n",
    "    with open(\"account_data_xxx.csv\", 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(new_data)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2a4012fca6975ccb4e2908886d96de946d5fe4261c9ff5ee375ddfd35668e36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
